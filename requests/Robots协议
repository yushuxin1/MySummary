1  网络爬虫的尺寸
        小规模，数据量小，爬取速度不敏感----->Requests库-----》爬取网页、玩转网页(90%)
        中规模，数据规模较大，爬取速度敏感---->Scrapy库------》爬取网站、爬取系列网站
        大规模，搜索引擎，爬取速度关键------->定制开发--------》爬取全网
2  网络爬虫的限制
    来源审查：判断User-Agent进行限制
        检查来访HTTP协议头的User-Agent域，只响应浏览器或好友爬虫的访问
    发布公告：Robots协议
        告知所有爬虫网站的爬取策略，要求爬虫遵守
3  Robots协议
    网络爬虫排除标准
    作用：网站告知网络爬虫哪些页面可以抓取，哪些不行
    形式：在网站根目录下的robots.txt文件
    基本语法：User-Agent     Disallow   *代表所有  /代表根目录
4  Robots协议的使用
    网络爬虫：自动或人工识别robots.txt，再进行内容爬取
    约束性：Robots协议是建议但非约束性，网络爬虫可以不遵守，但存在法律风险